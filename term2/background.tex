\chapter{Background}

Drug discovery is an expensive and long-term business. It takes US\$1.8 billion over a period of 13.5 years to develop a new drug \citep{716}. Figure \ref{fig:NewDrugApprovals} \citep{686} shows that in 2009 alone, only 24 new drugs were approved for marketing in the United States, well below the level required to secure the future of the pharmaceutical industry, which has been struggling with decreasing approval numbers for more than a decade. This is particularly remarkable because the level of investment in pharmaceutical R\&D (Research and Development) has dramatically increased by 12\% on average year-on-year since 1970 and at present to about US\$46 billion per year. Therefore drug discovery is economy driven \textit{per se}. Complementing expensive laboratory experiments with low-cost computer simulations is obviously the right way to go.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{Background/NewDrugApprovals.png}
\caption{New drug approvals and R\&D investments by PhRMA-member companies from 1970 to 2009. Figure reprinted from \citep{686}.}
\label{fig:NewDrugApprovals}
\end{figure}

\section{Protein-Ligand Docking}

Protein-ligand docking is an essential ingredient of computer-aided drug discovery. It tries to find inhibitors of viral proteins. Take the HIV virus for example (Figure \ref{fig:HIV} \citep{296}). The virus comprises several protein enzymes, which play an important role in replication. The reverse transcriptase reversely transcribes viral RNA into viral DNA. The integrase integres viral DNA into human genomic DNA in infected cells. The protease assemblies viral RNA and viral proteins into a new mature virus. If the viral proteins are inhibited, the replication cycle will be blocked. The inhibitors are typically small compounds called ligands. Protein-ligand docking therefore aims to discover inhibitory ligands of pharmaceutical protein targets of therapeutic interest.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{Background/HIV.jpg}
\caption{Replication cycle of HIV/AIDS. Figure reprinted from \citep{296}.}
\label{fig:HIV}
\end{figure}

Protein-ligand docking is a method which predicts the preferred conformation and binding affinity of a small ligand when bound to a macro protein to form a stable complex. A conformation refers to a vector of position, orientation, and torsions if any (Figure ). A binding affinity suggests how well the interactions formed between the ligand and the protein. Empirically speaking, it is the overall effect of various chemical interactions involved, such as van der Waals force, electrostatic force, hydrogen bonding, hydrophobic interactions, stack interactions, and the like.

Treating a docking program as a black box, its input includes the 3D structures of a protein and a ligand, while its output includes several predicted conformations and their predicted binding affinity. For the protein input, thanks to the rapid evolution of X-ray crystallography and NMR (Nuclear Magnetic Resonance) technologies, more and more 3D structures of biological macromolecules at atomic level have been revealed and deposited into the world's largest repository PDB (Protein Data Bank) \citep{540,537}. As of 4 Sep 2012, there are 84,381 structures in PDB. For the ligand input, the ZINC database \citep{532,1178} contains over 21 million purchasable compounds in ready-to-dock, 3D formats. In addition, the PubChem database \citep{526} is a public repository for biological properties of small molecules, containing biological test results for more than
700,000 compounds. The PDBbind database \citep{529,530} and the CSAR NRC HiQ Set \citep{857,960} are collections of binding affinities for protein-ligand complexes with known 3D structures. The refined set of PDBbind v2011 and the two sets of CSAR NRC HiQ Set 24Sept2010 comprise 2,455 and 343 protein-ligand complexes respectively, with experimentally determined binding affinity data (Kd or Ki). For the output, Chimera \citep{1219}, VMD \citep{1220}, AutoDockTools4 \citep{596}, PoseView \citep{748} LigPlot+ \citep{951} there are a few statistical metrics %

%statistical framework
%SLR \citep{489}
%comparison \citep{490}

%docking poses clustering
%AuPosSOM \citep{598}

Treating a docking program as a white box, it consists of two typical components, an algorithm to explore the conformational space of the ligand and the protein, and a scoring function to predict binding affinity given a conformation. Over the years, dozens of docking programs have been developed, such as DOCK, AutoDock 4 \citep{596}, AutoDock Vina \citep{595}, QuickVina \citep{1193}, PLANTS \citep{610,607}, FITTED \citep{602}, and CRDOCK \citep{1200}. Likewise, dozens of scoring functions have also been developed, such as RF-Score \citep{564}, SFCscore \citep{581}, LISA \citep{775}, and NNScore 2.0 \citep{977}. Some methods have been comprehensively evaluated and compared. Refer to survey papers for a more complete list \citep{493,922} and for program comparison \citep{556,637}.

%Local search optimizer
%MiniMuDS \citep{776}

Among the many docking programs, AutoDock Vina \citep{595} (hereafter Vina for short) is a competitive one. It's free and open source. It runs faster than its predecessor AutoDock 4 \citep{596} by an order of magnitude when benchmarking on virtual screening for HIV protease inhibitors \citep{556}. Released in 2010, Vina has been cited by 117 other publications and adopted by many researchers \citep{609}. Indeed, it is intensively used in our research projects too. In Vina, the binding affinity is evaluated as free energy. The lower the free energy, the higher the binding affinity.%Pymol plugin for AutoDock/Vina \citep{609}. MOLA: a bootable, self-configuring system for virtual screening using AutoDock4Vina on computer clusters \citep{773}

Virtual screening can be regarded as a massive version of docking. It docks a database of drug-like ligands to a viral protein of interest, ranks them according to their predicted binding affinity, and shortlists the best ones for further investigation. Statistical frameworks and assessments have been established for evaluation and result selection \citep{489,491,769,583,582}. In reality, docking and virtual screening have successful applications for drug discovery \citep{495,498,751,503,752,757,506,738,761,763,766,736}.

In addition to docking program development, there are also a great many successful case studies of using protein-ligand docking programs to discover novel and potent ligands for pharmacological proteins of therpeutic interest. To name a few, Vina was used for docking studies on the HEPT derivatives of HIV-1 veverse transcriptase \citep{843}, for side-chain residue flexibility study of VEGFR-2 (vascular endothelial growth factor receptor 2), a known protein target for anti-angiogenic agents \citep{1084}, and for identification of novel inhibitors of sirtuin 2, a NAD\textsuperscript{+}-dependent histone deacetylase enzyme \citep{1177}. Such exciting success stories prove the real power of protein-ligand docking for computer-aided drug discovery.

\section{Ligand Synthesis}

%Ligand design programs
%Review \citep{367,472,474,1006}
%MORPH \citep{365}
%GANDI \citep{369}
%GARLig \citep{471}
%LigBuilder 2 \citep{749}
%AutoT&T \citep{780}
%CrystalDock \citep{954}
%3D-QSAR \citep{1036}
%AutoClickChem \citep{1051}
%LigMerge \citep{1181}

%library
%e-Drug3D \citep{1125}

Virtual screening tries to discover promising ligands out of existing databases. Apparently the diversity of its outcome is limited to the diversity of the database. In other words, virtual screening will fail if the database contains no promising ligands at all.

In contrast, computational synthesis produces novel molecular structures with desired pharmacological properties. It helps to explore a much larger chemical space for novel drugs. Figure \ref{igrow:LigandDesign} \citep{363} illustrates three kinds of strategies for ligand design. A number of compounds that evolved from fragments have entered the clinic, and the approach is increasingly accepted as an additional route to identifying new hits in inhibitor design \citep{363,470}.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{igrow/LigandDesign.png}
\caption{Ligand design strategies. Figure reprinted from \citep{363}.}
\label{igrow:LigandDesign}
\end{figure}

A computational synthesis program is confronted with a virtually infinite search space. The number of chemically feasible, drug-like molecules has been estimated to be in the order of 10\textsuperscript{60} to 10\textsuperscript{100} \citep{1104}, from which the most promising candidates have to be selected and synthesized. Rather than the systematic construction and evaluation of each individual compound, computational synthesis programs rely on the principle of local optimization, which does not necessarily lead to the globally optimal solution. In fact, most software implementations \citep{466,749} are non-deterministic, and rely on some kind of stochastic structure optimization.

Among the many ligand synthesis programs, AutoGrow \citep{466} is a representative one which implements genetic algorithm to create a population of ligands. It is the only ligand synthesis program that uses Vina \citep{595} as external docking engine for the selection operator. It is free and open source. However, it requires messy configurations and its performance is hardly considered to be amazing. Hence its user base is rather limited and has been cited by merely 8 other publications since it was born in 2009. It is used as a baseline tool in our research projects.

\section{Software as a Service}

Ten Simple Rules for Getting Ahead as a Computational Biologist. Make software and website count \citep{260}
Ten Simple Rules for Providing a Scientific Web Resource \citep{677}
DOCK Blaster \citep{557}
iScreen \citep{899} compacted web server for TCM docking and followed by customized de novo drug design.
FORECASTER \citep{1012}
VSDMIP \citep{848} non-free
ViewDock TDW \citep{559}, ChemDoodle version
%CPORT \citep{650}
%iCanPlot \citep{1028}
%e-Drug3D \citep{1125}

\section{General-Purpose Computing on GPU}

The modern GPU has evolved from a fixed-function graphics pipeline to a programmable parallel processor with extremely high computational throughput and tremendous memory bandwidth at an affordable price. The past 5 years have seen a fruitful of algorithms for computer-aided drug discovery being ported to the GPU and gaining orders of magnitude of speedup over single threaded CPU counterparts. To name a few, such GPU-accelerated applications include binding site mapping \citep{722}, protein database search \citep{189}, compound selection \citep{750}, molecular docking \citep{723,652,779,969}, chemical similarity calculation \citep{726,881}, molecular dynamics \citep{373,374}, molecular shape comparison \citep{491}, data clustering \citep{932}, visualization \citep{986}.
%Performance evaluation of hybrid programming patterns for large CPU/GPU heterogeneous clusters \citep{1172}

As of June 2012, NVIDIA’s latest GPU architecture is codenamed ``Kepler" with its full implementation codenamed ``GK104", while AMD's latest GPU architecture is codenamed ``Southern Islands" with its full implementation codenamed ``Tahiti".

\subsection{NVIDIA GK104 and CUDA}

From the hardware perspective, the GK104-based GeForce GTX 680 GPU features 3.09 TFLOPS single-precision computing power and 128 GFLOPS double-precision computing power, 2GB GDDR5 memory with a bandwidth of 192GB/s, and a TDP (Thermal Design Power) of 195W.

Figure \ref{GPU:GeForceGTX680BlockDiagram} shows the block diagram of GeForce GTX 680, which consists of 4 GPCs (Graphics Processing Clusters), each having a dedicated raster engine and 2 SMX (next-generation Streaming Multiprocessors) units. With a total of 8 SMX units, the GeForce GTX 680 has 1536 CUDA Cores.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/GeForceGTX680BlockDiagram.png}
\caption{NVIDIA GeForce GTX680 block diagram. Source: NVIDIA.}
\label{GPU:GeForceGTX680BlockDiagram}
\end{figure}

Figure \ref{GPU:GeForceGTX680SMX} shows the block diagram of GK104 SMX unit, which features 192 IEEE 754-2008 compliant single-precision CUDA cores, 32 SFUs (Special Function Units), 4 warp schedulers, 8 instruction dispatch units, and 64KB of configurable shared memory / L1 cache. Each CUDA core has fully pipelined floating-point and integer arithmetic logic units, while the SFUs handle fast approximate transcendental and graphics interpolation instructions.

The SMX schedules threads in groups of 32 parallel threads called warps. The 4 warp schedulers allow 4 warps to be issued and executed concurrently. Each warp scheduler is capable of dispatching 2 instructions per warp every clock in order to feed the execution resources of SMX.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/GeForceGTX680SMX.png}
\caption{NVIDIA GeForce GTX680 SMX. Source: NVIDIA.}
\label{GPU:GeForceGTX680SMX}
\end{figure}

From the software perspective, the GeForce GTX 680 supports CUDA (Compute United Device Architecture), and thus can execute programs written in C, C++, Fortran, and other languages. A CUDA program invokes functions called kernels that execute across parallel CUDA threads, which are organized into thread blocks and grids of thread blocks. The hierarchy of CUDA threads maps to the hierarchy of CUDA cores on the GPU; a GPU executes one or more grids; an SMX executes one or more thread blocks; and CUDA cores and other execution units in the SMX execute thread instructions from kernel compilation.

Figure \ref{GPU:CUDAMemoryHierarchy} shows the CUDA hierarchy of threads, blocks and grids, and their corresponding memory space. A CUDA thread within a thread block maintains a program counter and executes an instance of the kernel. It has a per-thread private memory space used for register spills, function calls, and C automatic array variables. A thread block is a set of concurrently executing threads that can cooperate among themselves through barrier synchronization and shared memory. It has a per-block shared memory space used for inter-thread communication, data sharing, and result sharing. A grid is an array of thread blocks that execute the same kernel, read inputs from global memory, write results to global memory, and synchronize between dependent kernel calls. Grids share results in global memory after kernel-wide synchronization.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/CUDAMemoryHierarchy.png}
\caption{CUDA hierarchy of threads, blocks, and grids, with corresponding per-thread private, per-block shared, and per-application global memory spaces. Source: NVIDIA.}
\label{GPU:CUDAMemoryHierarchy}
\end{figure}

\subsection{AMD Tahiti and OpenCL}

From the hardware perspective, the Tahiti-based Radeon HD 7970 GPU features 3.79 TFLOPS single-precision computing power and 947 GFLOPS double-precision computing power, 3GB GDDR5 memory with a bandwidth of 264GB/s, and a TDP of 250W.

Figure \ref{GPU:RadeonHD7970BlockDiagram} shows the block diagram of Radeon HD 7970, which consists of 32 GCN (Graphics Core Next) cores, each heaving 64 stream processors, translating to a total of 2048 stream processors.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/RadeonHD7970BlockDiagram.jpg}
\caption{AMD Radeon HD 7970 block diagram. Source: AMD.}
\label{GPU:RadeonHD7970BlockDiagram}
\end{figure}

Figure \ref{GPU:RadeonHD7970GCN} shows the block diagram of a GCN core, which features a scheduler, 4 SIMD-16 vector units, 4 64KB vector registers, a single scalar unit, 64KB of LDS (Local Data Share), and 16KB of L1 cache. The GCN core schedules threads in groups of 16 parallel threads called wavefronts. The 4 SIMD-16 vector units are capable of not only processing 4 wavefronts in 4 clock cycles, equivalent to one wavefront per cycle, but also handling special functions like transcendentals at a rate of 4 operations per clock cycle. The scalar unit assists with flow control and handles address generation for pointers. The L1 cache has an aggregate bandwidth of about 2 TB/s.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/RadeonHD7970GCN.png}
\caption{AMD Radeon HD 7970 GCN. Source: AMD.}
\label{GPU:RadeonHD7970GCN}
\end{figure}

Figure \ref{GPU:RadeonHD7970CacheHierarchy} shows the cache hierarchy of Radeon HD 7970. A group of 4 GCN cores shares a 16KB instruction cache and a 32KB scalar data cache. The GDS (Global Data Share) enables L1 cache synchronization across all the GCN cores, which communicate over a shared bus to 6 128KB L2 cache partitions, each associated with a 64-bit dual-channel memory controllers, for a total of 768KB of L2 cache. The L2 cache can transfer nearly 710GB/s at 925MHz.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{GPU/RadeonHD7970CacheHierarchy.jpg}
\caption{AMD Radeon HD 7970 cache hierarchy. Source: AMD.}
\label{GPU:RadeonHD7970CacheHierarchy}
\end{figure}

From the software perspective, the Radeon HD 7970 supports OpenCL (Open Computing Language) 1.2, and thus can execute programs written in C. There is a C++ wrapper for OpenCL 1.1. An OpenCL program invokes functions called kernels that execute across parallel work-items, which are organized into work-groups. The hierarchy of work-items maps to the hierarchy of stream processors on the GPU; a GPU executes one or more kernels; a GCN core executes one or more work-groups; and stream processors execute work-item instructions from kernel compilation.

Portability is the distinct feature that distinguishes OpenCL from CUDA. Multiple conformant implementations from AMD, NVIDIA, Intel, IBM, and embedded device vendors are shipping, fulfilling the philosophy of ``write once, execute everywhere".

\chapterend
